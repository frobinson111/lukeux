RESEARCH GAP ANALYSIS - SMOKE TEST PACKAGE
Generated: 12/29/2025

This package contains three fictional scenarios designed to test AI prompts
that identify gaps in user research. Each scenario includes:
- A product/service description
- Research inputs (what you feed to the AI)
- Expected gaps (what the AI should identify)

Use these to validate that your prompt correctly identifies missing user
perspectives, abilities, environments, and usage scenarios.


================================================================================
SCENARIO 1: HEALTHTRACK MOBILE APP
================================================================================

PRODUCT/SERVICE:
Mobile health tracking application for medication reminders and symptom logging

TARGET AUDIENCE:
Adults managing chronic conditions

--------------------------------------------------------------------------------
RESEARCH INPUTS (Provided to AI)
--------------------------------------------------------------------------------
Research Methodology:
• 12 user interviews conducted
• 8 usability testing sessions
• Online survey (n=156)

Participant Demographics:
• Age range: 28-45 years old
• All participants owned smartphones (iPhone or Android flagship models)
• 100% native English speakers
• All sessions conducted in participants' homes during weekday afternoons
• Average income: $75,000-$120,000
• All participants had college degrees or higher
• Technology proficiency: Self-reported as "comfortable" to "expert"

Research Activities:
• Participants completed 5 tasks including setting medication reminders, logging symptoms, and viewing health reports
• Tasks performed in quiet, well-lit environments
• Average session duration: 45 minutes
• All participants used touchscreen gestures fluently
• No time constraints imposed during testing

Key Findings:
• 92% found the interface "intuitive"
• Average task completion rate: 87%
• Participants appreciated the detailed data visualization features

--------------------------------------------------------------------------------
EXPECTED GAPS (For Validation)
--------------------------------------------------------------------------------
1. No participants with vision impairments or who use screen readers
2. Older adults (65+) who are primary users of chronic condition management apps were excluded
3. No participants with motor impairments or tremors common in chronic conditions
4. No testing under distraction or stress (e.g., during symptom flare-ups)
5. Budget/lower-end smartphones not represented
6. Non-English speakers excluded despite health apps serving diverse populations
7. No participants with cognitive impairments or memory issues
8. Testing excluded real-world scenarios like medication reminders during sleep or work




================================================================================
SCENARIO 2: QUICKPAY BUSINESS BANKING PLATFORM
================================================================================

PRODUCT/SERVICE:
Web-based business banking platform for small business owners

TARGET AUDIENCE:
Small business owners managing accounts, payments, and payroll

--------------------------------------------------------------------------------
RESEARCH INPUTS (Provided to AI)
--------------------------------------------------------------------------------
Research Methodology:
• 20 contextual inquiry sessions
• 15 remote moderated usability tests
• Card sorting exercise (n=25)
• Analytics review of existing platform

Participant Profile:
• All participants were business owners for 5+ years
• Company size: 10-50 employees
• All used desktop computers with large monitors (24" or larger)
• High-speed broadband internet (100+ Mbps)
• Sessions conducted during regular business hours (9am-5pm)
• All participants managed their own accounting
• 100% had prior experience with at least 2 other banking platforms
• All held bachelor's degrees in business or related fields
• Age range: 35-52

Research Environment:
• All sessions in private offices
• Participants used their own computers
• Full keyboard and mouse access
• No interruptions during 60-90 minute sessions

Tasks Evaluated:
• Reviewing account balances and transaction history
• Initiating ACH transfers
• Processing payroll for employees
• Generating quarterly financial reports
• Setting up automated bill payments

Results:
• Task success rate: 85%
• Average time on task met benchmarks
• Participants valued detailed transaction filters and bulk operations

--------------------------------------------------------------------------------
EXPECTED GAPS (For Validation)
--------------------------------------------------------------------------------
1. New business owners with less than 1 year experience not represented
2. No participants who delegate banking tasks to employees or bookkeepers
3. Mobile-only users excluded (critical for business owners working off-site)
4. No testing in high-pressure scenarios (urgent payments, payroll deadlines)
5. Participants with lower financial literacy or no business education excluded
6. No users with dyscalculia or difficulties processing numerical information
7. Shared computer environments not considered (security/privacy implications)
8. Slow or unstable internet connections not tested
9. No participants using assistive technologies (screen magnification, voice control)
10. Non-native English speakers excluded despite serving immigrant business owners




================================================================================
SCENARIO 3: LEARNHUB ONLINE EDUCATION PLATFORM
================================================================================

PRODUCT/SERVICE:
E-learning platform for professional certification courses

TARGET AUDIENCE:
Working professionals seeking career advancement

--------------------------------------------------------------------------------
RESEARCH INPUTS (Provided to AI)
--------------------------------------------------------------------------------
Research Methodology:
• 18 one-on-one interviews
• 10 diary studies (2 weeks each)
• Tree testing for navigation structure
• A/B testing on 3 course page designs (n=500)

Participant Characteristics:
• Currently employed full-time in corporate settings
• Age: 26-38 years old
• All pursuing certification in tech-related fields (project management, data analytics, UX design)
• Median household income: $85,000
• Education: All had existing bachelor's degrees
• 100% described themselves as "digitally savvy"
• All owned laptops and had dedicated home office spaces
• Reliable high-speed internet access
• All participants had completed at least one online course previously
• Native English speakers only
• Recruitment through LinkedIn and professional networks

Study Conditions:
• Diary study entries made during evenings or weekends at participants' convenience
• Interviews conducted via Zoom with video on
• All participants used visual course materials (videos, slides, infographics)
• Average study environment: quiet, minimal distractions
• Participants had flexibility to pause and resume courses

Platform Usage Evaluated:
• Course discovery and enrollment
• Video lecture viewing and note-taking
• Completing quizzes and assignments
• Participating in discussion forums
• Downloading certificates upon completion

Findings:
• 89% completed their enrolled course
• Strong preference for video content over text
• Participants valued self-paced learning structure
• Discussion forums had low engagement (22% participation)

--------------------------------------------------------------------------------
EXPECTED GAPS (For Validation)
--------------------------------------------------------------------------------
1. No participants juggling multiple jobs or inflexible work schedules
2. Learners with hearing impairments or who need captions/transcripts not included
3. Non-traditional learners without prior degrees excluded
4. No participants with learning disabilities (dyslexia, ADHD)
5. Older workers (50+) seeking career transitions not represented
6. Limited internet bandwidth or data cap constraints not considered
7. Shared device usage (family computers) not evaluated
8. Non-English speakers or ESL learners excluded
9. No participants in caregiving roles with interrupted study time
10. Testing excluded learning in transit or on mobile devices
11. Participants with neurodivergent cognitive styles not represented
12. No evaluation of accessibility for visual course materials for blind/low-vision users



================================================================================
USAGE INSTRUCTIONS
================================================================================

1. Copy the "Research Inputs" section for any scenario
2. Paste it into your AI prompt/tool
3. Compare the AI's output against the "Expected Gaps" list
4. Evaluate:
   - Did the AI identify the critical gaps?
   - Were findings evidence-based (tied to the input data)?
   - Did it avoid vague conclusions or unsupported assumptions?
   - Did it explicitly call out accessibility and experience-level gaps?
   - Did it avoid giving recruitment or solution recommendations?

================================================================================
